{
  
    
        "post0": {
            "title": "Basic Preprocessing for NLP",
            "content": "%reload_ext autoreload %autoreload 2 %matplotlib inline . import os import glob from io import open import pandas as pd import numpy as np import re . import nltk nltk.download(&quot;popular&quot;) . [nltk_data] Downloading collection &#39;popular&#39; [nltk_data] | [nltk_data] | Downloading package cmudict to /root/nltk_data... [nltk_data] | Package cmudict is already up-to-date! [nltk_data] | Downloading package gazetteers to /root/nltk_data... [nltk_data] | Package gazetteers is already up-to-date! [nltk_data] | Downloading package genesis to /root/nltk_data... [nltk_data] | Package genesis is already up-to-date! [nltk_data] | Downloading package gutenberg to /root/nltk_data... [nltk_data] | Package gutenberg is already up-to-date! [nltk_data] | Downloading package inaugural to /root/nltk_data... [nltk_data] | Package inaugural is already up-to-date! [nltk_data] | Downloading package movie_reviews to [nltk_data] | /root/nltk_data... [nltk_data] | Package movie_reviews is already up-to-date! [nltk_data] | Downloading package names to /root/nltk_data... [nltk_data] | Package names is already up-to-date! [nltk_data] | Downloading package shakespeare to /root/nltk_data... [nltk_data] | Package shakespeare is already up-to-date! [nltk_data] | Downloading package stopwords to /root/nltk_data... [nltk_data] | Package stopwords is already up-to-date! [nltk_data] | Downloading package treebank to /root/nltk_data... [nltk_data] | Package treebank is already up-to-date! [nltk_data] | Downloading package twitter_samples to [nltk_data] | /root/nltk_data... [nltk_data] | Package twitter_samples is already up-to-date! [nltk_data] | Downloading package omw to /root/nltk_data... [nltk_data] | Package omw is already up-to-date! [nltk_data] | Downloading package wordnet to /root/nltk_data... [nltk_data] | Package wordnet is already up-to-date! [nltk_data] | Downloading package wordnet_ic to /root/nltk_data... [nltk_data] | Package wordnet_ic is already up-to-date! [nltk_data] | Downloading package words to /root/nltk_data... [nltk_data] | Package words is already up-to-date! [nltk_data] | Downloading package maxent_ne_chunker to [nltk_data] | /root/nltk_data... [nltk_data] | Package maxent_ne_chunker is already up-to-date! [nltk_data] | Downloading package punkt to /root/nltk_data... [nltk_data] | Package punkt is already up-to-date! [nltk_data] | Downloading package snowball_data to [nltk_data] | /root/nltk_data... [nltk_data] | Package snowball_data is already up-to-date! [nltk_data] | Downloading package averaged_perceptron_tagger to [nltk_data] | /root/nltk_data... [nltk_data] | Package averaged_perceptron_tagger is already up- [nltk_data] | to-date! [nltk_data] | [nltk_data] Done downloading collection popular . True . Mount your Google Drive, using &#39;google.colab&#39; library. The contents of the drive are available under the folder : &#39;/content/gdrive/My Drive&#39;. We will store our data csv files in the &#39;data/&#39; folder, inside our drive. . from google.colab import drive drive.mount(&#39;/content/gdrive&#39;) . Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(&#34;/content/gdrive&#34;, force_remount=True). . data_location = &#39;/content/gdrive/My Drive/data/consumer_complaints.csv&#39; . def find_files(path): return glob.glob(path) . data_file_list = find_files(data_location) . for file in data_file_list: print(file) . /content/gdrive/My Drive/data/consumer_complaints.csv . Read your CSV File into a Pandas DataFrame object . df = pd.read_csv(data_location) . /usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False. interactivity=interactivity, compiler=compiler, result=result) . Let&#39;s get an over view of our data. . df.head() . date_received product sub_product issue sub_issue consumer_complaint_narrative company_public_response company state zipcode tags consumer_consent_provided submitted_via date_sent_to_company company_response_to_consumer timely_response consumer_disputed? complaint_id . 0 08/30/2013 | Mortgage | Other mortgage | Loan modification,collection,foreclosure | NaN | NaN | NaN | U.S. Bancorp | CA | 95993 | NaN | NaN | Referral | 09/03/2013 | Closed with explanation | Yes | Yes | 511074 | . 1 08/30/2013 | Mortgage | Other mortgage | Loan servicing, payments, escrow account | NaN | NaN | NaN | Wells Fargo &amp; Company | CA | 91104 | NaN | NaN | Referral | 09/03/2013 | Closed with explanation | Yes | Yes | 511080 | . 2 08/30/2013 | Credit reporting | NaN | Incorrect information on credit report | Account status | NaN | NaN | Wells Fargo &amp; Company | NY | 11764 | NaN | NaN | Postal mail | 09/18/2013 | Closed with explanation | Yes | No | 510473 | . 3 08/30/2013 | Student loan | Non-federal student loan | Repaying your loan | Repaying your loan | NaN | NaN | Navient Solutions, Inc. | MD | 21402 | NaN | NaN | Email | 08/30/2013 | Closed with explanation | Yes | Yes | 510326 | . 4 08/30/2013 | Debt collection | Credit card | False statements or representation | Attempted to collect wrong amount | NaN | NaN | Resurgent Capital Services L.P. | GA | 30106 | NaN | NaN | Web | 08/30/2013 | Closed with explanation | Yes | Yes | 511067 | . We will use the &#39;consumer_complaint_narrative&#39; column. For our current purpose, we do not need rows which have no text in that column. Drop all the columns where &#39;consumer_complaint_narrative&#39; column value is absent . cust_complaint_df = df[df[&#39;consumer_complaint_narrative&#39;].notnull()] . cust_complaint_df.head() . date_received product sub_product issue sub_issue consumer_complaint_narrative company_public_response company state zipcode tags consumer_consent_provided submitted_via date_sent_to_company company_response_to_consumer timely_response consumer_disputed? complaint_id . 190126 03/19/2015 | Debt collection | Other (i.e. phone, health club, etc.) | Cont&#39;d attempts collect debt not owed | Debt was paid | XXXX has claimed I owe them {$27.00} for XXXX ... | NaN | Diversified Consultants, Inc. | NY | 121XX | Older American | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | No | 1290516 | . 190135 03/19/2015 | Consumer Loan | Vehicle loan | Managing the loan or lease | NaN | Due to inconsistencies in the amount owed that... | NaN | M&amp;T Bank Corporation | VA | 221XX | Servicemember | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | No | 1290492 | . 190155 03/19/2015 | Mortgage | Conventional fixed mortgage | Loan modification,collection,foreclosure | NaN | In XX/XX/XXXX my wages that I earned at my job... | NaN | Wells Fargo &amp; Company | CA | 946XX | NaN | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | Yes | 1290524 | . 190207 03/19/2015 | Mortgage | Conventional fixed mortgage | Loan servicing, payments, escrow account | NaN | I have an open and current mortgage with Chase... | NaN | JPMorgan Chase &amp; Co. | CA | 900XX | Older American | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | Yes | 1290253 | . 190208 03/19/2015 | Mortgage | Conventional fixed mortgage | Credit decision / Underwriting | NaN | XXXX was submitted XX/XX/XXXX. At the time I s... | NaN | Rushmore Loan Management Services LLC | CA | 956XX | Older American | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | Yes | 1292137 | . Let&#39;s view the quality of text in &#39;consumer_complaint_narrative&#39; column of the data frame . sample = cust_complaint_df[cust_complaint_df.index == 190126][[&#39;consumer_complaint_narrative&#39;]].values[0] print(sample) . [&#39;XXXX has claimed I owe them {$27.00} for XXXX years despite the PROOF of PAYMENT I sent them : canceled check and their ownPAID INVOICE for {$27.00}! nThey continue to insist I owe them and collection agencies are after me. nHow can I stop this harassment for a bill I already paid four years ago? n&#39;] . Now, define your pre-processing function. We will perform the following actions: . Convert all upper case letters to lower case | Replace the following characters with spaces [&#39;/&#39;, &#39;(&#39;, &#39;)&#39;, &#39;{&#39;, &#39;}&#39;, &#39;[&#39;,&#39;]&#39;,&#39;|&#39;, &#39;@&#39;, &#39;,&#39;, &#39;;&#39;] | Remove the following characters from the text [&#39;^&#39;, &#39;0-9&#39;, &#39;a-z&#39;, &#39;#&#39;, &#39;+&#39;, &#39;_&#39;] | Remove the masking character &#39;X&#39; from the text | Remove all stop words | Remove all numbers | from nltk.corpus import stopwords CONVERT_TO_SPACE_REGEX = re.compile(&#39;[/(){} [ ] |@,;]&#39;) BAD_CHARACTERS_REGEX = re.compile(&#39;[^0-9a-z #+_]&#39;) STOPWORDS = set(stopwords.words(&#39;english&#39;)) def text_pre_processor(text): text = text.lower() text = CONVERT_TO_SPACE_REGEX.sub(&#39; &#39;, text) text = BAD_CHARACTERS_REGEX.sub(&#39;&#39;, text) text = text.replace(&#39;x&#39;, &#39;&#39;) text = &#39; &#39;.join(word for word in text.split() if word not in STOPWORDS) return text . cust_complaint_df = cust_complaint_df.reset_index(drop=True) cust_complaint_df[&#39;consumer_complaint_narrative&#39;] = cust_complaint_df[&#39;consumer_complaint_narrative&#39;].apply(text_pre_processor) cust_complaint_df[&#39;consumer_complaint_narrative&#39;] = cust_complaint_df[&#39;consumer_complaint_narrative&#39;].str.replace(&#39; d+&#39;, &#39;&#39;) . Let&#39;s view the quality of text after applying the pre-processing to each text datum in the &#39;consumer_complaint_narrative&#39; column . cust_complaint_df.head() . date_received product sub_product issue sub_issue consumer_complaint_narrative company_public_response company state zipcode tags consumer_consent_provided submitted_via date_sent_to_company company_response_to_consumer timely_response consumer_disputed? complaint_id . 0 03/19/2015 | Debt collection | Other (i.e. phone, health club, etc.) | Cont&#39;d attempts collect debt not owed | Debt was paid | claimed owe years despite proof payment sent ... | NaN | Diversified Consultants, Inc. | NY | 121XX | Older American | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | No | 1290516 | . 1 03/19/2015 | Consumer Loan | Vehicle loan | Managing the loan or lease | NaN | due inconsistencies amount owed told bank amou... | NaN | M&amp;T Bank Corporation | VA | 221XX | Servicemember | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | No | 1290492 | . 2 03/19/2015 | Mortgage | Conventional fixed mortgage | Loan modification,collection,foreclosure | NaN | wages earned job decreased almost half knew tr... | NaN | Wells Fargo &amp; Company | CA | 946XX | NaN | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | Yes | 1290524 | . 3 03/19/2015 | Mortgage | Conventional fixed mortgage | Loan servicing, payments, escrow account | NaN | open current mortgage chase bank # chase repor... | NaN | JPMorgan Chase &amp; Co. | CA | 900XX | Older American | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | Yes | 1290253 | . 4 03/19/2015 | Mortgage | Conventional fixed mortgage | Credit decision / Underwriting | NaN | submitted time submitted complaint dealt rushm... | NaN | Rushmore Loan Management Services LLC | CA | 956XX | Older American | Consent provided | Web | 03/19/2015 | Closed with explanation | Yes | Yes | 1292137 | . Let&#39;s view the quality of text post-processing . sample = cust_complaint_df[cust_complaint_df.index == 0][[&#39;consumer_complaint_narrative&#39;]].values[0] print(sample) . [&#39;claimed owe years despite proof payment sent canceled check ownpaid invoice continue insist owe collection agencies stop harassment bill already paid four years ago&#39;] .",
            "url": "https://vasu014.github.io/backprop-revelations/2020/03/27/nlp-preprocessing.html",
            "relUrl": "/2020/03/27/nlp-preprocessing.html",
            "date": " • Mar 27, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://vasu014.github.io/backprop-revelations/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://vasu014.github.io/backprop-revelations/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am Vasu Bhardwaj. I’m an experienced product developer. I am comfortable with working on the backend, the frontend and DevOps, depending on the task at hand, with some experience in managing small teams. I completed my B.Tech in Software Engineering from Delhi Technological University. I thrive on caffeine and love to explore the coffee shops everywhere I go. This blog is a means for me to keep track of various things I’m learning on my journey in the tech world. Here is my resume. . . . . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://vasu014.github.io/backprop-revelations/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}